{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedSlotMachineEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(PairedSlotMachineEnv, self).__init__()\n",
    "\n",
    "        # Define action space: pick option 1 or option 2 in the current pair\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        \n",
    "        # Observation space: represent each machine with its index and indicator status (0 or 1)\n",
    "        self.observation_space = spaces.MultiDiscrete([8, 2, 8, 2])\n",
    "\n",
    "        # Define slot machine points and probabilities\n",
    "        self.points = {\n",
    "            'A': 10, 'B': 10, 'C': 1, 'D': 1,\n",
    "            'E': 10, 'F': 10, 'G': 1, 'H': 1\n",
    "        }\n",
    "        self.probabilities = {\n",
    "            'A': 0.75, 'B': 0.25, 'C': 0.75, 'D': 0.25,\n",
    "            'E': 0.75, 'F': 0.25, 'G': 0.75, 'H': 0.25\n",
    "        }\n",
    "\n",
    "        # Original pairs for Learning Phase and new pairs for Transfer Phase\n",
    "        self.learning_pairs = [('A', 'B'), ('C', 'D'), ('E', 'F'), ('G', 'H')]\n",
    "        self.transfer_pairs = [('A', 'C'), ('B', 'D'), ('E', 'H'), ('F', 'G')]\n",
    "        self.transfer_phase = False  # Start in learning phase by default\n",
    "        self.current_pair = None\n",
    "        self.rewards = None\n",
    "        self.indicators = None\n",
    "\n",
    "    def set_transfer_phase(self, transfer: bool):\n",
    "        \"\"\"Toggle between learning and transfer phases.\"\"\"\n",
    "        self.transfer_phase = transfer\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        # Start with a random pair from the current phase\n",
    "        self.current_pair = self._get_random_pair()\n",
    "        # Set up the initial observation with pre-sampled rewards and indicators\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _get_machine_index(self, machine):\n",
    "        # Map machine labels to indices for the observation space\n",
    "        machine_indices = {'A': 0, 'B': 1, 'C': 2, 'D': 3,\n",
    "                           'E': 4, 'F': 5, 'G': 6, 'H': 7}\n",
    "        return machine_indices[machine]\n",
    "\n",
    "    def _get_random_pair(self):\n",
    "        # Select from learning pairs or transfer pairs based on the phase\n",
    "        pairs = self.transfer_pairs if self.transfer_phase else self.learning_pairs\n",
    "        pair = pairs[np.random.randint(len(pairs))]\n",
    "        # Randomly shuffle the order with 50% probability\n",
    "        if np.random.rand() < 0.5:\n",
    "            pair = pair[::-1]\n",
    "        return pair\n",
    "\n",
    "    def _get_indicator_status(self, machine, reward_given):\n",
    "        # 95% chance of showing the indicator if reward is given, or hiding it if not\n",
    "        if reward_given:\n",
    "            return 1 if np.random.rand() < 0.95 else 0\n",
    "        else:\n",
    "            return 0 if np.random.rand() < 0.95 else 1\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # Generate machine indices for the current pair\n",
    "        machine_indices = [self._get_machine_index(m) for m in self.current_pair]\n",
    "\n",
    "        # Sample rewards and indicator statuses once, store them in instance variables\n",
    "        self.rewards = []\n",
    "        self.indicators = []\n",
    "        \n",
    "        for i, machine in enumerate(self.current_pair):\n",
    "            reward_given = np.random.rand() < self.probabilities[machine]\n",
    "            reward = self.points[machine] if reward_given else 0\n",
    "            self.rewards.append(reward)\n",
    "            indicator = self._get_indicator_status(machine, reward_given)\n",
    "            self.indicators.append(indicator)\n",
    "\n",
    "        # Return observation as [machine index, indicator] pairs\n",
    "        return np.array([machine_indices[0], self.indicators[0], machine_indices[1], self.indicators[1]])\n",
    "\n",
    "    def step(self, action):\n",
    "        # Use the pre-sampled reward for the selected action\n",
    "        reward = self.rewards[action]\n",
    "        \n",
    "        # Select a new random pair for the next step\n",
    "        self.current_pair = self._get_random_pair()\n",
    "        \n",
    "        # Get the new observation (with updated pre-sampled rewards and indicators)\n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, False, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"Current pair: {self.current_pair[0]} (with indicator {self.indicators[0]}) \"\n",
    "              f\"vs {self.current_pair[1]} (with indicator {self.indicators[1]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 371  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 5    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010977835 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00278     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 987         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 294        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01155796 |\n",
      "|    clip_fraction        | 0.0842     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.663     |\n",
      "|    explained_variance   | 0.00174    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.54e+03   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    value_loss           | 3.38e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00970521 |\n",
      "|    clip_fraction        | 0.0662     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.625     |\n",
      "|    explained_variance   | 0.000486   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.8e+03    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.00969   |\n",
      "|    value_loss           | 4.14e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850138 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.000153    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.07e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    value_loss           | 4.9e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007316199 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.000113    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.64e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    value_loss           | 5.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036943518 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 6e-05        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.81e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    value_loss           | 5.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006529154 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.466      |\n",
      "|    explained_variance   | 3.82e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    value_loss           | 5.64e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004354776 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 3e-05       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.14e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 6.84e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027288774 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 2.31e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.35e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 6.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031240727 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.368       |\n",
      "|    explained_variance   | 1.88e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+03     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 6.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031053477 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.363       |\n",
      "|    explained_variance   | 1.32e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.19e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 7.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 274          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020033976 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.351       |\n",
      "|    explained_variance   | 1.09e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.73e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    value_loss           | 6.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 274          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033285315 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.33        |\n",
      "|    explained_variance   | 9.24e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.1e+03      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 6.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027048846 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.312       |\n",
      "|    explained_variance   | 7.03e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.99e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 6.97e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002058322 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 4.65e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.8e+03     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 7.51e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026659314 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.297       |\n",
      "|    explained_variance   | 4.83e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.06e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 6.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016260198 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.275       |\n",
      "|    explained_variance   | 3.28e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 7.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027395498 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.268       |\n",
      "|    explained_variance   | 2.92e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.44e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 7.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023191187 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.252       |\n",
      "|    explained_variance   | 2.32e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.27e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 7.12e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014485737 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.245       |\n",
      "|    explained_variance   | 2.32e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.55e+03     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 7.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001915161 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 2.21e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.63e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    value_loss           | 7.73e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002901841 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 8.94e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.45e+03    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 7.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001905628 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | 1.43e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.36e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    value_loss           | 7.05e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009205773 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 8.94e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.52e+03     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    value_loss           | 7.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030531015 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.216       |\n",
      "|    explained_variance   | 6.56e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.01e+03     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    value_loss           | 6.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017927019 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 7.75e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.31e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    value_loss           | 6.92e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002035907 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.197      |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+03    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    value_loss           | 7.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022735163 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | 7.15e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    value_loss           | 6.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023573036 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 5.36e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 7.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019243947 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 5.36e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.03e+03     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 6.81e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003025419 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 5.36e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.34e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 7.59e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016925307 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.198       |\n",
      "|    explained_variance   | 2.98e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.14e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    value_loss           | 6.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012812319 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 4.17e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.4e+03      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 7.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010838129 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 4.77e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.8e+03      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000831    |\n",
      "|    value_loss           | 8.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024922322 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23e+03     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 7.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030300557 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.184       |\n",
      "|    explained_variance   | 3.58e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.31e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 6.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 288          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013744241 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.181       |\n",
      "|    explained_variance   | 4.17e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.6e+03      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 7.08e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002392771 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 7.42e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020382213 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 7.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002089022 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.174      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82e+03    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 7.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 320          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025971355 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.179       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.81e+03     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 7.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 328          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021973005 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 7.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 335          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014390328 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.187       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.62e+03     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    value_loss           | 7.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 343          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028546867 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.47e+03     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 7.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 351          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026348135 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.178       |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.43e+03     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    value_loss           | 7.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003344535 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.178      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 7.2e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 366          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029450846 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.177       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.42e+03     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 7.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018768465 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.162       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.67e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 7.16e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22ea80cb350>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the environment\n",
    "env = PairedSlotMachineEnv()\n",
    "check_env(env)\n",
    "\n",
    "# Create the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, gamma=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pair: E (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: C (with indicator 1) vs D (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: H (with indicator 0) vs G (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: F (with indicator 1) vs E (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: A (with indicator 1) vs B (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: E (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: F (with indicator 0) vs E (with indicator 0)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: H (with indicator 0) vs G (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: E (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: E (with indicator 0) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: G (with indicator 1) vs H (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: A (with indicator 0) vs B (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: A (with indicator 0) vs B (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: G (with indicator 1) vs H (with indicator 1)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: H (with indicator 0) vs G (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: C (with indicator 0) vs D (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: B (with indicator 1) vs A (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: E (with indicator 1) vs F (with indicator 1)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: H (with indicator 1) vs G (with indicator 1)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: D (with indicator 0) vs C (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: F (with indicator 1) vs E (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: C (with indicator 1) vs D (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: F (with indicator 1) vs E (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: A (with indicator 0) vs B (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: F (with indicator 1) vs E (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: E (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: B (with indicator 1) vs A (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: H (with indicator 0) vs G (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: C (with indicator 1) vs D (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: A (with indicator 1) vs B (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: G (with indicator 1) vs H (with indicator 1)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: A (with indicator 0) vs B (with indicator 1)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: E (with indicator 1) vs F (with indicator 1)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: G (with indicator 1) vs H (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: G (with indicator 1) vs H (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: H (with indicator 1) vs G (with indicator 1)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: H (with indicator 1) vs G (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: H (with indicator 0) vs G (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: G (with indicator 1) vs H (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: G (with indicator 1) vs H (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: F (with indicator 0) vs E (with indicator 0)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: D (with indicator 0) vs C (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: E (with indicator 1) vs F (with indicator 1)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: E (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: D (with indicator 0) vs C (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: G (with indicator 1) vs H (with indicator 1)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: E (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: H (with indicator 0) vs G (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: B (with indicator 0) vs A (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: A (with indicator 1) vs B (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "for _ in range(50):\n",
    "    env.render()\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    print(f\"Action taken: {action}, Reward received: {reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pair: G (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: B (with indicator 0) vs D (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: B (with indicator 0) vs D (with indicator 0)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: B (with indicator 0) vs D (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: G (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: B (with indicator 0) vs D (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: F (with indicator 0) vs G (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: G (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: B (with indicator 1) vs D (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: H (with indicator 0) vs E (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: D (with indicator 0) vs B (with indicator 0)\n",
      "Action taken: 0, Reward received: 0\n",
      "Current pair: D (with indicator 0) vs B (with indicator 1)\n",
      "Action taken: 1, Reward received: 10\n",
      "Current pair: B (with indicator 0) vs D (with indicator 0)\n",
      "Action taken: 1, Reward received: 0\n",
      "Current pair: E (with indicator 0) vs H (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: G (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n",
      "Current pair: A (with indicator 1) vs C (with indicator 1)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: F (with indicator 1) vs G (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: B (with indicator 0) vs D (with indicator 1)\n",
      "Action taken: 1, Reward received: 1\n",
      "Current pair: F (with indicator 1) vs G (with indicator 0)\n",
      "Action taken: 0, Reward received: 10\n",
      "Current pair: G (with indicator 1) vs F (with indicator 0)\n",
      "Action taken: 0, Reward received: 1\n"
     ]
    }
   ],
   "source": [
    "# Switch to Transfer Phase\n",
    "env.set_transfer_phase(True)\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# Test agent in Transfer Phase\n",
    "for _ in range(20):\n",
    "    env.render()\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    print(f\"Action taken: {action}, Reward received: {reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estanciaRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
